#BeginSection(header)
	/* this file was originately generated as export from old parser, then later completed with manual additions to form DESSBAS (DD=Deutsch SS=Stolze-Schrey BAS=Grundschrift) */
	//
	// Die Grundschrift Stolze-Schrey soll nun nach folgenden Prinzipien neu designt werden:
	// 
	// Zeichen:
	// Prinzipiell sollen schönere Zeichen gestaltet werden. Dies wird erreicht durch:
	// - bessere Platzierung der Zeichenknoten (Verwendung von VPAINT wo möglich, der Rest wird nach wie vor handeditiert)
	// - Korrektur der Spannungen (geradere Modellierung von Zeichen-Rücken, schönere Anfangs- und Endbögen)
	// - bessere Zeichenabstände in Engschreibung: Zeichen werden neu als "Rohzeichen" modelliert, d.h. nur mit width (offset 0) ohne additional width before/after (offsets 4 + 5).
	//   Die Regeln werden um einen "spacer" ergänzt, der individuelle Abstände zwischen den Zeichen einfügt.
	//
	// Technisch sollen folgende Prinzipien eingehalten werden:
	// - es soll nur die SE1 rev0 genutzt werden (also keine parallelen Rotationsachsen und keine proportionalen/orthogonalen Punkte), dies um sicherzustellen, dass die Definitionen 100% mit der
	//   SE1 kompatibel sind)
	// - die Zeichen werden für eine Neigung von 60 Grad optimiert (dies damit die Knoten trotz horizontaler Schiebung möglichst optimal platziert werden)
	//
	// Wenn nötig (d.h. wenn damit keine schönen Zeichen generiert werden können) soll auf spezielle Funktionen der SE1, die darauf ausgerichtet waren, den Editionsaufwand und die Datenmengen 
	// zu reduzieren, verzichtet werden:
	// - auf late entry und early exit knots wird verzichtet => stattdessen wird für jede Variante ein eigenes Zeichen definiert
	// - auf token combiner und shifter wird verzichtet => stattdessen wird für jede Variante ein eigenes Zeichen definiert
	// - eventuell sollen die Zeichen auch um neue Knoten erweitert werden, um eine feinere Ausgestaltung zu erreichen (z.B. bei der Schattierung), allerdings soll dies vorsichtig gehandhabt
	//   werden, da es allenfalls Sinn macht, Optimierung der Schattierung später automatisch vorzunehmen (ähnlich wie bei der geplanten SE2)
	//
	// Regeln:
	// - es soll konsequent darauf geachtet werden, mit der STD-Form einen Kompatibilitätspunkt im Parsprozess zu generieren
	// - da mehr Zeichen definiert werden, soll konsequent darauf geachtet werden, dass die Bezeichnungen der Tokens einer einheitlichen Schreibweise folgen (diese soll im Font und innerhalb
	//   der Regeln verwendet werden)
	// - Reste aus dem alten "Trickster" sollen entfernt werden
	// - generelles Ausmisten und Ausräumen der Regeln
	/  - es wird ein Spacer ergänzt, der individuelle Abstände zwischen Zeichen (in Abhängikeit auch von Hoch-/Tiefstellung etc. einfügen kann)
	//
	// Schreibweise:
	// = ein Zeichen am Wortanfang (z.B. [F=]) oder Wortende (z.B. [=NG])
	// ^ ein höher gestelltes Zeichen (z.B. [^CH]) oder Variante vor höhergestelltem Zeichen (z.B. [AR5^])
	// _ ein tiefer gestelltes Zeichen (z.B. [_N])
	// @ ein Verbundzeichen (z.B. [@L] oder [@R], die mit anderen Zeichen verbunden werden)
	// 0..9 bei runden Zeichen: Anknüpfpunkt (z.B. [@R6] = Zeichen R mit Anknüpfpunkt bei 6 Uhr, also im Fusspunkt)
	// # technische Zeichen (z.B. [#WS] = wide shadowed, eine weite, schattierte Verbindung, also ä im System Stolze-Schrey; [#5] = spacer mit Abstand 5px)
	// +- Gross- oder Kleinschreibung bei Blockschriftzeichen (z.B. [A+] = grosses A, [A-] = kleines A)
	// & geschriebene Vokale oder Häkchen (z.B. [&I] oder [&E])
        // -1 bei Aufstrich-t: wie viel tiefer weitergeschrieben wird (z.B. [&T-1] in Verbindung mit [B])
	#BeginSubSection(session)
		"prefixes_list" := "in, kon, ge, zu, un, be, bei, ein, um, ur, anti, ver, inter, mit, ent, auf, ab, an, er, vor, wie?-?der, durch, ein, der, des, dem, her, ge-?gen, hin, zer, recht, sam-?men, un-?ter, aus, rück, da, nach, zwi-?schen, hin-?ten, hin-?ter, weg, ü-?ber, miss, dar, wei-?ter, los, lang, so, lieb, schief, scharf, statt, tief, wahr, weich, weis, wett, wohl, zwangs, fehl, fest, frei, gleich, kalt, kund, kurz, gut, nie-?der, wor?";
		"stems_list" := "gangen, fähr, brochen, kannt, ra-?de(?:s-?te?)?[rsnm]?, höf, ständ, bun-?de-?n(?:e[nmrs]?)?, müt, schwenden, tüm";
		"suffixes_list" := "[kh]ei-?t(?:s|en)?, li-?ch(?:(?:e-?r)(?:e[srn]?)?)?, nis(?:sen?)?, w(?:ie|o|ann|as|e[rnm]), los(?:(?:es)?e[snmr]?)?, bar(?:(?:st)?e[rnsm]?)?, sam(?:(?:st)e[rsnm]?)?, hin, her, so, sch(?:a|ä)f-?t(?:(?:s\|?|e-?[rn]?)(?:in-?(?:nen)?))?, un-?te-?r(?:(?:st)?e?[smnr]?), seits"; // use non caputuring groups! (?:)
		//"title_text" := "new prefixes";
	#EndSubSection(session)
	#BeginSubSection(analyzer)
		"ebe(-?)n" => "e-be$1n";  // bug in phpSyllable: eben is not hyphenated!?
		"oder" => "o-der"; 	// same ...
		// probably, phpSyllable doesn't separate VCV at the beginning
		// because it doesn't want to separate just 1 vowel (would be ugly in a text)
		// so, it never separates the first vowel in that case
		// => therefore, correct that "bug" (feature;-) here in a more general way
		"([aeiouAEIOU]|ä|ö|ü|Ä|Ö|Ü)([bcdfghjklmnprstvwxz])([aeiouAEIOU]|ä|ö|ü|Ä|Ö|Ü)" => "$1-$2$3";

		// hm ... must say that phpSyllable doesn't do a very reliable job ...
		// Ausweichthema for example: separation "Ausweich-thema" is NOT recognized ...
		// only possibility to patch this would be in the dictionary of phpSyllable
		// (which - if I'm right - is based on TEX)

		"([Uu]n)z-([aeiou])" => "$1+z$2"; // phpSyllable does that wrong ...
		"\|ge$" => "-ge"; 	// correct ge- prefix (recognized as word)

		"([Dd])e-?nen" => "$1en+en";

		"^([Nn])eu\|e" => "$1eu-e";

		"([Ii])n-ter-" => "$1n-ter+";

		"\|dun(-?)g(s|en)?$" => "-dun$1g$2"; // Neugründung

		"([Hh])e-?r-?aus-?" => "$1er+aus+";
		"da-ma(-?)l" => "da+ma$1l";
		"un(-?|\||\+)te(-?)r" => "un-te$2r"; 
		"(\+|\|)([bd])e([nrsm]?)$" => "-$2e$3";
		"([WwNn])ie\|de(-?)r\+" => "$1ie-de$2r|";
		"([WwNn])ie\|de(-?)r" => "$1ie-de$2r";
		"([Nn])ie\|ma" => "$1ie-ma";

		"\+lie-g" => "|lie-g"; // daniederliegen
		"([Ss])ie\|ben" => "$1ie-ben";
		"zäh\|lun-gen$" => "zäh-lun-gen";
		"([Mm])it\|tag" => "$1it-tag";
		"([Vv])iel\|leicht" => "$1iel-leicht";
		"^([Pp])ro\|" => "$1ro-";
		"e\|ren$" => "e-ren";	// näheren
		"(\+|\|)ge(-?)n(e[nrs]?)?$" => "-ge$2n$3";
		"\|([kh])ei\|t(.?.?)$" => "=$1ei-t$2"; 
		"^[Ee]r(\|)" => "{ER}"; // prefix or infix er
		"(\|)er(\|)" => "{ER}"; // infix er
		"[Aa]n\+?de(-|\|)?r(en?)?" => "an-de$1r$2";

		// mark prefixes that have not been recognized
		"^([Vv])er-ant-" => "$1er+ant+";
		"\|ver-ant-" => "|ver+ant+";

		"in-dem" => "in+dem";
		"zu-dem" => "zu+dem";
		"^([Gg]e)[-+]?(gen)\|" => "$1-$2+";
		"^(Ü|ü)(-?)ber-" => "$1$2ber+"; 
		"([Bb]e)-?(rei-?t)" => "$1+$2";
		"([Uu]r)-?(teil)" => "|$1+teil"; 	// isn't recognized because 2nd word starts with vowel
		"([Jj]e)\|?(de)" => "$1-$2";
		"([Bb]e)-(son-de)" => "$1+$2";
		"([Ee]r)-(f[auie])" => "$1+$2";  // c'est osé ...
		"([Ee]r)-(kl(?:[aeiou]|ä))" => "$1+$2";
		"([Gg]e)-(n(?:u|ü))" => "$1+$2";
		
		"([Ee])r-folg" => "$1r+folg";

		"ungs-an" => "ungs|an"; // terrible "hacks" ... :-)
		"\|an-" => "|an+";

		"([Ww])ar\|um" => "$1a-rum";
		"([Bb])e-?que(-?)m" => "$1e+que$2m";
		"([Pp])fle-?ge\|r" => "$1fle-ge-r"; // Pflege-Rinnen (Computers are stupid ... :)
		"([Aa])-?me-?ri-?ka\|ni" => "$1-me-ri-ka-ni";	// Amerika-Nische (Computers are stupid ... :)
		//"([Kk])i(-?)lo\|" => "$1i$2lo+"; // Kilometer: shorting [et] ...
		"#seits" => "|seits";

		// prefix in-
		"^([Ii])n-(?!ter)" => "$1n+";

		// trying to recognize more ge-/be- prefixes: rule: ends with -en(..) or -t(..)
		"\+([bg])e-(.*)-(.*)(en(?:(?:-?s-?t|e-?r)?e[nrsm]?))?" => "+$1e+$2-$3$4";
		"^([bg])e-(.*)-(.*)(en(?:(?:-?s-?t|e-?r)?e[nrsm]?))?" => "$1e+$2-$3$4";
		"\+([bg])e-(.*)-(.*)(-?t(?:(?:es-?t|e-?r)?e[nrsm]?))?" => "+$1e+$2-$3$4";
		"^([bg])e-(.*)-(.*)(-?t(?:(?:es-?t|e-?r)?e[nrsm]?))?" => "$1e+$2-$3$4";

		// same for ver-
		"\+([Vv])er-(.*)-(.*)(en(?:(?:-?s-?t|e-?r)?e[nrsm]?))?" => "+$1er+$2-$3$4";
		"^([Vv])er-(.*)-(.*)(en(?:(?:-?s-?t|e-?r)?e[nrsm]?))?" => "$1er+$2-$3$4";
		"\+([Vv])er-(.*)-(.*)(-?t(?:(?:es-?t|e-?r)?e[nrsm]?))?" => "+$1er+$2-$3$4";
		"^([Vv])er-(.*)-(.*)(-?t(?:(?:es-?t|e-?r)?e[nrsm]?))?" => "$1er+$2-$3$4";

		// be- + #er(in)(nen) // be- + ung
		"([Bb]e)-(.*)-(.*?)(e-?r)([sn]|in(?:-?nen)?)?$" => "$1+$2-$3$4$5";
		"([Bb]e)-(.*-)(.*)(un-?g(?:s|en)?)" => "$1+$2$3$4";	

		// recorrect be-/ge- before gerundium
		"([bg]e)\+(.*)(n-?d)(e[rnsm]?)$" => "$1-$2$3$4";
		"([bg]e)\+(.*)(n-?d)(e[rnsm]?)\|" => "$1-$2$3$4|";
		// and correct the correction ...
		"([Bb]e)-?(geis-?ter)" => "$1+$2";

		// an-
		"([Aa]n)-(.*)-(lich)" => "$1+$2#lich";

		"^([Aa]uf|[Vv]er|[Zz]u)-(.*)(ung)(en)?$" => "$1+$2$3$4";
		"\+(auf|ver|zu)-(.*)(ung)(en)?$" => "+$1+$2$3$4";


	#EndSubSection(analyzer)
#EndSection(header)
